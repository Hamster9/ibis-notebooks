{
 "metadata": {
  "name": "",
  "signature": "sha256:297c0f4d726889c59f0a1d5d4c08942dd6194a3060aaf0ff34434adbbddcdc7d"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "import posixpath\n",
      "import shutil\n",
      "import sys"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import ibis\n",
      "ic = ibis.impala_connect(host='localhost')\n",
      "hdfs = ibis.hdfs_connect(host='localhost', port=5070)\n",
      "con = ibis.make_client(ic, hdfs_client=hdfs)\n",
      "con"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's create a test data warehouse in Parquet format for testing and users"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_db = 'ibis_testing'\n",
      "test_db_location = '/__ibis/ibis-testing'\n",
      "test_data_dir = 'ibis-testing-data'\n",
      "test_data_hdfs_loc = '/__ibis/ibis-testing-data'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "con.hdfs.put(test_data_hdfs_loc, test_data_dir, verbose=True, overwrite=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "if con.exists_database(test_db):\n",
      "    con.drop_database(test_db, drop_tables=True)\n",
      "con.create_database(test_db, path=test_db_location)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "contents = con.hdfs.ls(test_data_hdfs_loc)\n",
      "\n",
      "tpch_parquet_paths = [x for x in contents if 'tpch_' in x]\n",
      "for path in tpch_parquet_paths:\n",
      "    head, table_name = posixpath.split(path)\n",
      "    con.parquet_file(path, name=table_name, database=test_db, persist=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "to_scrape = [('tpch', x) for x in con.list_tables(database='tpch')]\n",
      "to_scrape.append(('functional', 'alltypes'))\n",
      "for db, tname in to_scrape:\n",
      "    table = con.table(tname, database=db)\n",
      "    new_name = '{}_{}'.format(db, tname)\n",
      "    con.create_table(new_name, table, database=test_db)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "if os.path.exists(test_data_dir):\n",
      "    shutil.rmtree(test_data_dir)\n",
      "con.hdfs.get(test_db_location, pjoin(test_data_dir, 'parquet'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "avro_path = '/test-warehouse/tpch.region_avro'\n",
      "con.hdfs.get(avro_path, pjoin(test_data_dir, 'avro', 'tpch.region'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "csv_path = '/ibis-test/csv-test'\n",
      "con.hdfs.get(csv_path, pjoin(test_data_dir, 'csv'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}