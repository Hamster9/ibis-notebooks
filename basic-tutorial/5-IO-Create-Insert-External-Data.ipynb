{
 "metadata": {
  "name": "",
  "signature": "sha256:f1aec947d0edb299bec2431a5c9bc89a0799cd260888774bba39942677a9c802"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import ibis\n",
      "\n",
      "ic = ibis.impala_connect(host='localhost', database='ibis_testing')\n",
      "hdfs = ibis.hdfs_connect(port=5070)\n",
      "con = ibis.make_client(ic, hdfs_client=hdfs)\n",
      "\n",
      "ibis.options.interactive = True"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Creating new Impala tables from Ibis expressions\n",
      "---\n",
      "\n",
      "Suppose you have an Ibis expression that "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "table = con.table('functional_alltypes')\n",
      "\n",
      "t2 = table[table, (table.bigint_col - table.int_col).name('foo')]\n",
      "\n",
      "expr = (t2\n",
      "        [t2.bigint_col > 30]\n",
      "        .group_by('string_col')\n",
      "        .aggregate([t2.foo.min().name('min_foo'),\n",
      "                    t2.foo.max().name('max_foo'),\n",
      "                    t2.foo.sum().name('sum_foo')]))\n",
      "expr"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "  string_col  min_foo  max_foo  sum_foo\n",
        "0          6       54       54    39420\n",
        "1          4       36       36    26280\n",
        "2          7       63       63    45990\n",
        "3          8       72       72    52560\n",
        "4          5       45       45    32850\n",
        "5          9       81       81    59130"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To create a table in the database, use the connection's `create_table` method:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "con.create_table('testing_table', expr, database='ibis_testing')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "By default, this creates a table stored as **Parquet format** in HDFS. Support for views, external tables, configurable file formats, and so forth, will come in the future. Feedback on what kind of interface would be useful for that would help."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "con.table('testing_table')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "  string_col  min_foo  max_foo  sum_foo\n",
        "0          6       54       54    39420\n",
        "1          4       36       36    26280\n",
        "2          7       63       63    45990\n",
        "3          9       81       81    59130\n",
        "4          8       72       72    52560\n",
        "5          5       45       45    32850"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Tables can be similarly dropped with `drop_table`"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "con.drop_table('testing_table', database='ibis_testing')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Inserting data into existing Impala tables\n",
      "---\n",
      "\n",
      "The client's `insert` method can append new data to an existing table or overwrite the data that is in there."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Uploading / downloading data from HDFS\n",
      "---"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Queries on Parquet, Avro, and Delimited files in HDFS\n",
      "---"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Other helper functions for interacting with the database\n",
      "---\n",
      "- Listing and searching for available databases and tables\n",
      "- Getting table schemas\n",
      "- "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Dealing with Partitioned tables in Impala\n",
      "---"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Placeholder:** This is not yet implemented. If you have use cases, please let us know."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}