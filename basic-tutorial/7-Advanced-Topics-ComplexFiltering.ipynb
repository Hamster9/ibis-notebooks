{
 "metadata": {
  "name": "",
  "signature": "sha256:27d14a6bc0a15d5256d95a34bc1a480e0ce224e1229cf4e4fee8b314cfdd3fbe"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "More filtering mojo for your analytics\n",
      "===\n",
      "\n",
      "The filtering examples we've shown to this point have been pretty simple, either comparisons between columns or fixed values, or set filter functions like `isin` and `notin`. \n",
      "\n",
      "Ibis supports a number of richer analytical filters that can involve one or more of:\n",
      "\n",
      "- Aggregates computed from the same or other tables\n",
      "- Conditional aggregates (in SQL-speak these are similar to \"correlated subqueries\")\n",
      "- \"Existence\" set filters (equivalent to the SQL `EXISTS` and `NOT EXISTS` keywords)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import ibis\n",
      "\n",
      "ic = ibis.impala_connect(host='localhost', database='ibis_testing')\n",
      "hdfs = ibis.hdfs_connect(port=5070)\n",
      "con = ibis.make_client(ic, hdfs_client=hdfs)\n",
      "\n",
      "ibis.options.interactive = True"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Using scalar aggregates in filters\n",
      "---"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "table = con.table('functional.alltypes')\n",
      "table.limit(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 2,
       "text": [
        "     id bool_col  tinyint_col  smallint_col  int_col  bigint_col  float_col  \\\n",
        "0  3340     True            0             0        0           0        0.0   \n",
        "1  3341    False            1             1        1          10        1.1   \n",
        "2  3342     True            2             2        2          20        2.2   \n",
        "3  3343    False            3             3        3          30        3.3   \n",
        "4  3344     True            4             4        4          40        4.4   \n",
        "\n",
        "   double_col date_string_col string_col              timestamp_col  year  \\\n",
        "0         0.0        12/01/09          0        2009-12-01 00:00:00  2009   \n",
        "1        10.1        12/01/09          1        2009-12-01 00:01:00  2009   \n",
        "2        20.2        12/01/09          2 2009-12-01 00:02:00.100000  2009   \n",
        "3        30.3        12/01/09          3 2009-12-01 00:03:00.300000  2009   \n",
        "4        40.4        12/01/09          4 2009-12-01 00:04:00.600000  2009   \n",
        "\n",
        "   month  \n",
        "0     12  \n",
        "1     12  \n",
        "2     12  \n",
        "3     12  \n",
        "4     12  "
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We could always compute some aggregate value from the table and use that in another expression, or we can use a data-derived aggregate in the filter. Take the average of a column for example:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "table.double_col.mean()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "45.450000000000003"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "You can use this expression as a substitute for a scalar value in a filter, and the execution engine will combine everything into a single query rather than having to access Impala multiple times:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cond = table.bigint_col > table.double_col.mean()\n",
      "expr = table[cond & table.bool_col].limit(5)\n",
      "expr"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "     id bool_col  tinyint_col  smallint_col  int_col  bigint_col  float_col  \\\n",
        "0  1206     True            6             6        6          60        6.6   \n",
        "1  1208     True            8             8        8          80        8.8   \n",
        "2  1216     True            6             6        6          60        6.6   \n",
        "3  1218     True            8             8        8          80        8.8   \n",
        "4  1226     True            6             6        6          60        6.6   \n",
        "\n",
        "   double_col date_string_col string_col              timestamp_col  year  \\\n",
        "0        60.6        05/01/09          6 2009-05-01 00:06:00.150000  2009   \n",
        "1        80.8        05/01/09          8 2009-05-01 00:08:00.280000  2009   \n",
        "2        60.6        05/02/09          6 2009-05-02 00:16:00.600000  2009   \n",
        "3        80.8        05/02/09          8 2009-05-02 00:18:00.730000  2009   \n",
        "4        60.6        05/03/09          6 2009-05-03 00:26:01.500000  2009   \n",
        "\n",
        "   month  \n",
        "0      5  \n",
        "1      5  \n",
        "2      5  \n",
        "3      5  \n",
        "4      5  "
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Conditional aggregates\n",
      "---\n",
      "\n",
      "Suppose that we wish to filter using an aggregate computed conditional on some other expressions holding true. Using the TPC-H datasets, suppose that we want to filter customers based on the following criteria: Orders such that their amount exceeds the average amount for their sales region over the whole dataset. This can be computed any numbers of ways (such as joining auxiliary tables and filtering post-join)\n",
      "\n",
      "Again, from prior examples, here are the joined up tables with all the customer data:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "region = con.table('tpch.region')\n",
      "nation = con.table('tpch.nation')\n",
      "customer = con.table('tpch.customer')\n",
      "orders = con.table('tpch.orders')\n",
      "\n",
      "fields_of_interest = [customer,\n",
      "                      region.r_name.name('region'), \n",
      "                      orders.o_totalprice,\n",
      "                      orders.o_orderdate.cast('timestamp').name('odate')]\n",
      "\n",
      "tpch = (region.join(nation, region.r_regionkey == nation.n_regionkey)\n",
      "        .join(customer, customer.c_nationkey == nation.n_nationkey)\n",
      "        .join(orders, orders.o_custkey == customer.c_custkey)\n",
      "        [fields_of_interest])\n",
      "\n",
      "tpch.limit(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "   c_custkey              c_name                                 c_address  \\\n",
        "0     123314  Customer#000123314      nKPmaZi,OKhObOYSL3wc egXR4Vt99CXRclF   \n",
        "1     136777  Customer#000136777  Qy6YjXMy1jjCBkVDvnDThNMMLQG49wXEgIJ6DPLK   \n",
        "2      39136  Customer#000039136           afZJC1mWpwvsfKT0211ZD6NQXVGETfl   \n",
        "3      66958  Customer#000066958               h5jsmOq8nxf8Pz1Knqe GZdK4lh   \n",
        "4     127588  Customer#000127588         DbnvQxsG0,Nobhbj6n5cMUNPjfouzdFzH   \n",
        "\n",
        "   c_nationkey          c_phone c_acctbal c_mktsegment  \\\n",
        "0           15  25-884-345-1592   -686.40    MACHINERY   \n",
        "1           10  20-500-807-1549    -65.46    HOUSEHOLD   \n",
        "2            5  15-400-347-1643   5555.41    FURNITURE   \n",
        "3           18  28-393-112-1873   9160.79    MACHINERY   \n",
        "4           14  24-409-883-5840    358.38     BUILDING   \n",
        "\n",
        "                                           c_comment       region  \\\n",
        "0             ounts serve furiously. carefully expre       AFRICA   \n",
        "1  y regular foxes nag blithely among the careful...  MIDDLE EAST   \n",
        "2  y? express theodolites haggle against the bold...       AFRICA   \n",
        "3  ggle quickly after the carefully stealthy depo...         ASIA   \n",
        "4                  accounts wake slyly along the bli       AFRICA   \n",
        "\n",
        "  o_totalprice      odate  \n",
        "0    193846.25 1993-10-14  \n",
        "1     32151.78 1995-10-11  \n",
        "2    252004.18 1996-01-10  \n",
        "3    163243.98 1993-10-27  \n",
        "4    253724.56 1995-10-23  "
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In this particular case, filtering based on the conditional average `o_totalprice` by region requires creating a table view (similar to the self-join examples from earlier) that can be treated as a distinct table entity in the expression. This would **not** be required if we were computing a conditional statistic from some other table. So this is a little more complicated than some other cases would be:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "t2 = tpch.view()\n",
      "conditional_avg = t2[(t2.region == tpch.region)].o_totalprice.mean()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Once you've done this, you can use the conditional average in a filter expression"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "amount_filter = tpch.o_totalprice > conditional_avg\n",
      "tpch[amount_filter].limit(10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "   c_custkey              c_name                              c_address  \\\n",
        "0     133885  Customer#000133885                           EVK76gJeTspw   \n",
        "1     148102  Customer#000148102             sqd6wCIoHZ6qMdVveUERJraOO1   \n",
        "2      86575  Customer#000086575                     zM8VpTc8mN8FH3hhSB   \n",
        "3     110077  Customer#000110077                WYMxagzV8I4oZ70p,udJLpo   \n",
        "4      38347  Customer#000038347                             EX9sekdiT3   \n",
        "5      58699  Customer#000058699                 0CnSyWM,oVtMelVLCqqt0    \n",
        "6      93424  Customer#000093424  X3KU415KQl8Ocuibp2OTD5uUyGfmcy4DHAoiu   \n",
        "7     100867  Customer#000100867                           68dihxX4Q3G2   \n",
        "8      16721  Customer#000016721    bUJvWuJCja8qqABKR1VFo5cYHgSkLTUWTRq   \n",
        "9      15046  Customer#000015046                         2eqiNOfoz0CkoP   \n",
        "\n",
        "   c_nationkey          c_phone c_acctbal c_mktsegment  \\\n",
        "0           24  34-956-563-4308   6723.55   AUTOMOBILE   \n",
        "1            6  16-318-581-1666   8906.57     BUILDING   \n",
        "2           14  24-285-938-5455   2829.32     BUILDING   \n",
        "3           13  23-554-808-3156   3028.96    FURNITURE   \n",
        "4            4  14-304-282-9706   7656.60     BUILDING   \n",
        "5           17  27-535-620-9127    -90.50    MACHINERY   \n",
        "6            1  11-855-298-3754   7307.87    MACHINERY   \n",
        "7           18  28-908-868-8184   3777.50     BUILDING   \n",
        "8           22  32-461-228-4896   1080.16    MACHINERY   \n",
        "9            6  16-453-428-6615   4738.36    MACHINERY   \n",
        "\n",
        "                                           c_comment       region  \\\n",
        "0  mptotes use blithely furiously regular escapad...      AMERICA   \n",
        "1  eas. deposits integrate along the slyly ironic...       EUROPE   \n",
        "2  en hockey players. even foxes grow slyly above...       AFRICA   \n",
        "3   pending platelets against the slyly silent de...  MIDDLE EAST   \n",
        "4  ending deposits hang blithely along the reques...  MIDDLE EAST   \n",
        "5            packages promise furiously express acco      AMERICA   \n",
        "6   express platelets. express packages use furio...      AMERICA   \n",
        "7                    slyly. slyly final instructions         ASIA   \n",
        "8                      ly. carefully unusual instruc       EUROPE   \n",
        "9  frays above the busy, regular requests doze am...       EUROPE   \n",
        "\n",
        "  o_totalprice      odate  \n",
        "0    160843.35 1992-06-22  \n",
        "1    201463.59 1997-09-12  \n",
        "2    158056.07 1993-11-27  \n",
        "3    229979.86 1998-05-03  \n",
        "4    215157.60 1993-06-23  \n",
        "5    165289.72 1995-10-23  \n",
        "6    272125.55 1993-12-01  \n",
        "7    351080.95 1994-01-14  \n",
        "8    163299.21 1994-06-20  \n",
        "9    311931.95 1992-10-06  "
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "By looking at the table sizes before and after applying the filter you can see the relative size of the subset taken. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tpch.count()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "1500000"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tpch[amount_filter].count()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "711969"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Or even group by year and compare before and after:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "year = tpch.odate.year().name('year')\n",
      "\n",
      "pre_sizes = tpch.group_by(year).size()\n",
      "post_sizes = tpch[amount_filter].group_by(year).size()\n",
      "\n",
      "percent = ((post_sizes['count'] / pre_sizes['count'].cast('double'))\n",
      "           .name('fraction'))\n",
      "\n",
      "expr = (pre_sizes.join(post_sizes, pre_sizes.year == post_sizes.year)\n",
      "        [pre_sizes.year, \n",
      "         pre_sizes['count'].name('pre_count'),\n",
      "         post_sizes['count'].name('post_count'),\n",
      "         percent])\n",
      "expr"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 10,
       "text": [
        "   year  pre_count  post_count  fraction\n",
        "0  1994     227597      108087  0.474905\n",
        "1  1996     228626      108757  0.475698\n",
        "2  1993     226645      107703  0.475206\n",
        "3  1992     227089      107815  0.474770\n",
        "4  1998     133623       63551  0.475599\n",
        "5  1995     228637      108315  0.473742\n",
        "6  1997     227783      107741  0.472998"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\"Existence\" filters\n",
      "---\n",
      "\n",
      "Some filtering involves checking for the existence of a particular value in a column of another table, or amount the results of some value expression. This is common in many-to-many relationships, and can be performed in numerous different ways, but it's nice to be able to express it with a single concise statement and let Ibis compute it optimally.\n",
      "\n",
      "Here's some examples:\n",
      "\n",
      "- Filter down to customers having at least one open order\n",
      "- Find customers having no open orders with 1-URGENT status\n",
      "- Find stores (in the stores table) having the same name as a vendor (in the vendors table).\n",
      "\n",
      "We'll go ahead and solve the first couple of these problems using the TPC-H tables to illustrate the API:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "customer = con.table('tpch.customer')\n",
      "orders = con.table('tpch.orders')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "orders.limit(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 12,
       "text": [
        "   o_orderkey  o_custkey o_orderstatus o_totalprice o_orderdate  \\\n",
        "0           1      36901             O    173665.47  1996-01-02   \n",
        "1           2      78002             O     46929.18  1996-12-01   \n",
        "2           3     123314             F    193846.25  1993-10-14   \n",
        "3           4     136777             O     32151.78  1995-10-11   \n",
        "4           5      44485             F    144659.20  1994-07-30   \n",
        "\n",
        "  o_orderpriority          o_clerk  o_shippriority  \\\n",
        "0           5-LOW  Clerk#000000951               0   \n",
        "1        1-URGENT  Clerk#000000880               0   \n",
        "2           5-LOW  Clerk#000000955               0   \n",
        "3           5-LOW  Clerk#000000124               0   \n",
        "4           5-LOW  Clerk#000000925               0   \n",
        "\n",
        "                                           o_comment  \n",
        "0                 nstructions sleep furiously among   \n",
        "1   foxes. pending accounts at the pending, silen...  \n",
        "2  sly final accounts boost. carefully regular id...  \n",
        "3  sits. slyly regular warthogs cajole. regular, ...  \n",
        "4  quickly. bold deposits sleep slyly. packages u...  "
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We introduce the `any` reduction:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "has_open_orders = ((orders.o_orderstatus == 'O') & \n",
      "                   (customer.c_custkey == orders.o_custkey)).any()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This is now a valid filter:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "customer[has_open_orders].limit(10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 14,
       "text": [
        "   c_custkey              c_name                              c_address  \\\n",
        "0          1  Customer#000000001                      IVhzIApeRb ot,c,E   \n",
        "1          2  Customer#000000002         XSTf4,NCwDVaWNe6tEgvwfmRchLXak   \n",
        "2          4  Customer#000000004                            XxVSJsLAGtn   \n",
        "3          5  Customer#000000005           KvpyuHCplrB84WgAiGV6sYpZq7Tj   \n",
        "4          7  Customer#000000007         TcGe5gaZNgVePxU5kRrvXBfkasDTea   \n",
        "5          8  Customer#000000008  I0B10bB0AymmC, 0PrRYBCP1yGJ8xcBPmWhl5   \n",
        "6         10  Customer#000000010     6LrEaV6KR6PLVcgl2ArL Q3rqzLzcT1 v2   \n",
        "7         11  Customer#000000011                PkWS 3HlXqwTuzrKg633BEi   \n",
        "8         13  Customer#000000013                nsXQu0oVjD7PM659uC3SRSp   \n",
        "9         14  Customer#000000014                        KXkletMlL2JQEA    \n",
        "\n",
        "   c_nationkey          c_phone c_acctbal c_mktsegment  \\\n",
        "0           15  25-989-741-2988    711.56     BUILDING   \n",
        "1           13  23-768-687-3665    121.65   AUTOMOBILE   \n",
        "2            4  14-128-190-5944   2866.83    MACHINERY   \n",
        "3            3  13-750-942-6364    794.47    HOUSEHOLD   \n",
        "4           18  28-190-982-9759   9561.95   AUTOMOBILE   \n",
        "5           17  27-147-574-9335   6819.74     BUILDING   \n",
        "6            5  15-741-346-9870   2753.54    HOUSEHOLD   \n",
        "7           23  33-464-151-3439   -272.60     BUILDING   \n",
        "8            3  13-761-547-5974   3857.34     BUILDING   \n",
        "9            1  11-845-129-3851   5266.30    FURNITURE   \n",
        "\n",
        "                                           c_comment  \n",
        "0  to the even, regular platelets. regular, ironi...  \n",
        "1  l accounts. blithely ironic theodolites integr...  \n",
        "2   requests. final, regular ideas sleep final accou  \n",
        "3  n accounts will have to unwind. foxes cajole a...  \n",
        "4  ainst the ironic, express theodolites. express...  \n",
        "5  among the slyly regular theodolites kindle bli...  \n",
        "6                    es regular deposits haggle. fur  \n",
        "7  ckages. requests sleep slyly. quickly even pin...  \n",
        "8  ounts sleep carefully after the close frays. c...  \n",
        "9                  , ironic packages across the unus  "
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For the second example, in which we want to find customers not having any open urgent orders, we write down the condition that they _do_ have some first:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "has_open_urgent_orders = ((orders.o_orderstatus == 'O') & \n",
      "                          (orders.o_orderpriority == '1-URGENT') & \n",
      "                          (customer.c_custkey == orders.o_custkey)).any()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now, we can negate this condition and use it as a filter:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "customer[-has_open_urgent_orders].count()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 16,
       "text": [
        "75801"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In this case, it is true that `customer.c_custkey` has no duplicate values, but that need not be the case. There could be multiple copies of any given value in either table column being compared, and the behavior will be the same (existence or non-existence is verified)."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}