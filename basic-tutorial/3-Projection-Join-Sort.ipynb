{
 "metadata": {
  "name": "",
  "signature": "sha256:6326f73f936b408380b3e9bb19b10dc04ec3f9fcbc301c124aa23b6e32dc45bc"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from ibis import api\n",
      "import ibis\n",
      "con = ibis.impala_connect(host='localhost')\n",
      "ibis.options.interactive = True"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Projections: adding/selecting columns\n",
      "===\n",
      "\n",
      "Projections are the general way for adding new columns to tables, or selecting or removing existing ones."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "table = con.table('functional.alltypes')\n",
      "table.limit(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 2,
       "text": [
        "    id bool_col  tinyint_col  smallint_col  int_col  bigint_col  float_col  \\\n",
        "0  900     True            0             0        0           0        0.0   \n",
        "1  901    False            1             1        1          10        1.1   \n",
        "2  902     True            2             2        2          20        2.2   \n",
        "3  903    False            3             3        3          30        3.3   \n",
        "4  904     True            4             4        4          40        4.4   \n",
        "\n",
        "   double_col date_string_col string_col              timestamp_col  year  \\\n",
        "0         0.0        04/01/09          0        2009-04-01 00:00:00  2009   \n",
        "1        10.1        04/01/09          1        2009-04-01 00:01:00  2009   \n",
        "2        20.2        04/01/09          2 2009-04-01 00:02:00.100000  2009   \n",
        "3        30.3        04/01/09          3 2009-04-01 00:03:00.300000  2009   \n",
        "4        40.4        04/01/09          4 2009-04-01 00:04:00.600000  2009   \n",
        "\n",
        "   month  \n",
        "0      4  \n",
        "1      4  \n",
        "2      4  \n",
        "3      4  \n",
        "4      4  "
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "First, the basics: selecting columns:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "proj = table['bool_col', 'int_col', 'double_col']\n",
      "\n",
      "proj.limit(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "  bool_col  int_col  double_col\n",
        "0     True        0         0.0\n",
        "1    False        1        10.1\n",
        "2     True        2        20.2\n",
        "3    False        3        30.3\n",
        "4     True        4        40.4"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "You can make a list of columns you want, too, and pass that:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "to_select = ['bool_col', 'int_col']\n",
      "table[to_select].limit(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "  bool_col  int_col\n",
        "0     True        0\n",
        "1    False        1\n",
        "2     True        2\n",
        "3    False        3\n",
        "4     True        4"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "You can also use the explicit `projection` or `select` functions"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "table.select(['int_col', 'double_col']).limit(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "   int_col  double_col\n",
        "0        0         0.0\n",
        "1        1        10.1\n",
        "2        2        20.2\n",
        "3        3        30.3\n",
        "4        4        40.4"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can add new columns by using named column expressions"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bigger_expr = (table.int_col * 2).name('bigger_ints')\n",
      "proj2 = table['int_col', bigger_expr]\n",
      "proj2.limit(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "   int_col  bigger_ints\n",
        "0        0            0\n",
        "1        1            2\n",
        "2        2            4\n",
        "3        3            6\n",
        "4        4            8"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Adding columns is a shortcut for projection. In Ibis, adding columns always produces a new table reference"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "table2 = table.add_column(bigger_expr)\n",
      "table2.limit(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "     id bool_col  tinyint_col  smallint_col  int_col  bigint_col  float_col  \\\n",
        "0  6080     True            0             0        0           0        0.0   \n",
        "1  6081    False            1             1        1          10        1.1   \n",
        "2  6082     True            2             2        2          20        2.2   \n",
        "3  6083    False            3             3        3          30        3.3   \n",
        "4  6084     True            4             4        4          40        4.4   \n",
        "\n",
        "   double_col date_string_col string_col              timestamp_col  year  \\\n",
        "0         0.0        09/01/10          0        2010-09-01 00:00:00  2010   \n",
        "1        10.1        09/01/10          1        2010-09-01 00:01:00  2010   \n",
        "2        20.2        09/01/10          2 2010-09-01 00:02:00.100000  2010   \n",
        "3        30.3        09/01/10          3 2010-09-01 00:03:00.300000  2010   \n",
        "4        40.4        09/01/10          4 2010-09-01 00:04:00.600000  2010   \n",
        "\n",
        "   month  bigger_ints  \n",
        "0      9            0  \n",
        "1      9            2  \n",
        "2      9            4  \n",
        "3      9            6  \n",
        "4      9            8  "
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In more complicated projections involving joins, we may need to refer to all of the columns in a same at once. This is how `add_column` works. We just pass the whole table in the projection:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "table.select([table, bigger_expr]).limit(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "     id bool_col  tinyint_col  smallint_col  int_col  bigint_col  float_col  \\\n",
        "0  5770     True            0             0        0           0        0.0   \n",
        "1  5771    False            1             1        1          10        1.1   \n",
        "2  5772     True            2             2        2          20        2.2   \n",
        "3  5773    False            3             3        3          30        3.3   \n",
        "4  5774     True            4             4        4          40        4.4   \n",
        "\n",
        "   double_col date_string_col string_col              timestamp_col  year  \\\n",
        "0         0.0        08/01/10          0        2010-08-01 00:00:00  2010   \n",
        "1        10.1        08/01/10          1        2010-08-01 00:01:00  2010   \n",
        "2        20.2        08/01/10          2 2010-08-01 00:02:00.100000  2010   \n",
        "3        30.3        08/01/10          3 2010-08-01 00:03:00.300000  2010   \n",
        "4        40.4        08/01/10          4 2010-08-01 00:04:00.600000  2010   \n",
        "\n",
        "   month  bigger_ints  \n",
        "0      8            0  \n",
        "1      8            2  \n",
        "2      8            4  \n",
        "3      8            6  \n",
        "4      8            8  "
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To use constants in projections, we have to use a special `literal` api, found in `ibis.api`"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from ibis import api\n",
      "\n",
      "foo_constant = api.literal(5).name('foo')\n",
      "table.select([table.bigint_col, foo_constant]).limit(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "   bigint_col  foo\n",
        "0           0    5\n",
        "1          10    5\n",
        "2          20    5\n",
        "3          30    5\n",
        "4          40    5"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Joins\n",
      "===\n",
      "\n",
      "Ibis attempts to provide good support for all the standard relational joins supported by Impala, Hive, and other relational databases.\n",
      "\n",
      "- inner, outer, left, right joins\n",
      "- semi and anti-joins\n",
      "\n",
      "To illustrate the joins we'll use the TPC-H tables for now"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "region = con.table('tpch.region')\n",
      "nation = con.table('tpch.nation')\n",
      "customer = con.table('tpch.customer')\n",
      "lineitem = con.table('tpch.lineitem')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "`region` and `nation` are connected by their respective `regionkey` columns"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "join_expr = region.r_regionkey == nation.n_regionkey\n",
      "joined = region.inner_join(nation, join_expr)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "If you have multiple join conditions, either compose them yourself (like filters) or pass a list to the join function\n",
      "\n",
      "    join_exprs = [cond1, cond2, cond3]\n",
      "    joined = table1.inner_join(table2, join_exprs)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Once you've joined tables, you don't necessarily have anything yet. I'll put it in big letters\n",
      "\n",
      "Joins are declarations of intent\n",
      "---\n",
      "\n",
      "After calling the join function (which validates the join condition, of course), you may perform any number of other operations:\n",
      "\n",
      "- Aggregation\n",
      "- Projection\n",
      "- Filtering\n",
      "\n",
      "and so forth. Most importantly, depending on your schemas, the joined tables may include overlapping column names that could create a conflict if not addressed directly. Some other systems, like pandas, handle this by applying suffixes to the overlapping column names and computing the fully joined tables immediately. We don't do this.\n",
      "\n",
      "So, with the above data, suppose we just want the region name and all the nation table data. We can then make a projection on the joined reference:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "table_ref = joined[nation, region.r_name.name('region')]\n",
      "table_ref.columns"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 12,
       "text": [
        "['n_nationkey', 'n_name', 'n_regionkey', 'n_comment', 'region']"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "table_ref.limit(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 13,
       "text": [
        "   n_nationkey     n_name  n_regionkey  \\\n",
        "0            0    ALGERIA            0   \n",
        "1            1  ARGENTINA            1   \n",
        "2            2     BRAZIL            1   \n",
        "3            3     CANADA            1   \n",
        "4            4      EGYPT            4   \n",
        "\n",
        "                                           n_comment       region  \n",
        "0   haggle. carefully final deposits detect slyly...       AFRICA  \n",
        "1  al foxes promise slyly according to the regula...      AMERICA  \n",
        "2  y alongside of the pending deposits. carefully...      AMERICA  \n",
        "3  eas hang ironic, silent packages. slyly regula...      AMERICA  \n",
        "4  y above the carefully unusual theodolites. fin...  MIDDLE EAST  "
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "agged = table_ref.aggregate([table_ref.n_name.count().name('nrows')], by=['region'])\n",
      "agged"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 14,
       "text": [
        "        region  nrows\n",
        "0       EUROPE      5\n",
        "1      AMERICA      5\n",
        "2  MIDDLE EAST      5\n",
        "3         ASIA      5\n",
        "4       AFRICA      5"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Things like `group_by` work with unmaterialized joins, too, as you would hope. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "joined.group_by(region.r_name).size()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 15,
       "text": [
        "        r_name  count\n",
        "0       EUROPE      5\n",
        "1      AMERICA      5\n",
        "2  MIDDLE EAST      5\n",
        "3         ASIA      5\n",
        "4       AFRICA      5"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Explicit join materialization\n",
      "---\n",
      "\n",
      "If you're lucky enough to have two table schemas with no overlapping column names (lucky you!), the join can be *materialized* without having to perform some other relational algebra operation:\n",
      "\n",
      "    joined = a.inner_join(b, join_expr).materialize()\n",
      "    \n",
      "Note that this is equivalent to doing\n",
      "\n",
      "    joined = a.join(b)[a, b]\n",
      "   \n",
      "i.e., joining and then selecting all columns from both joined tables."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Writing down join keys\n",
      "---\n",
      "\n",
      "In addition to having explicit comparison expressions as join keys, you can also write down column names, or use expressions referencing the joined tables, e.g.:\n",
      "\n",
      "    joined = a.join(b, [('a_key1', 'b_key2')])\n",
      "    \n",
      "    joined2 = a.join(b, [(left_expr, right_expr)])\n",
      "\n",
      "    joined3 = a.join(b, ['common_key'])\n",
      "\n",
      "These will be compared for equality when performing the join; if you want non-equality conditions in the join, you will have to form those yourself."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Join referential nuances\n",
      "---\n",
      "\n",
      "There's nothing to stop you from doing many joins in succession, and, in fact, with complex schemas it will be to your advantage to build the joined table references for your analysis first, then reuse the objects as you go:\n",
      "\n",
      "    joined_ref = (a.join(b, a.key1 == b.key2)\n",
      "                   .join(c, [a.key3 == c.key4, b.key5 == c.key6]))\n",
      "\n",
      "Note that, at least right now, you need to provide explicit comparison expressions (or tuples of column references) referencing the joined tables."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Aggregating joined table with metrics involving more than one base reference\n",
      "---\n",
      "\n",
      "Let's consider the case similar to the SQL query\n",
      "\n",
      "    SELECT a.key, sum(a.foo - b.bar) AS metric\n",
      "    FROM a\n",
      "      JOIN b\n",
      "        ON a.key = b.key\n",
      "    GROUP BY 1\n",
      "    \n",
      "I'll use a somewhat contrived example using the data we already have to show you what this looks like. Take the `functional.alltypes` table, and suppose we want to compute the **mean absolute deviation (MAD) from the hourly mean of the double_col**. Silly, I know, but bear with me.\n",
      "\n",
      "First, the hourly mean:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "table = con.table('functional.alltypes')\n",
      "\n",
      "hour_dim = table.timestamp_col.hour().name('hour')\n",
      "\n",
      "hourly_mean = (table.group_by(hour_dim)\n",
      "               .aggregate([table.double_col.mean().name('avg_double')]))\n",
      "hourly_mean"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 16,
       "text": [
        "   hour  avg_double\n",
        "0     4       45.45\n",
        "1     2       45.45\n",
        "2     0       45.45\n",
        "3     1       45.45\n",
        "4     5       45.45\n",
        "5     3       45.45"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Okay, great, now how about the MAD? The only trick here is that we can form an aggregate metric from the two tables, and we then have to join it later. Ibis **will not** figure out how to join the tables automatically for us. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mad = (table.double_col - hourly_mean.avg_double).abs().mean().name('MAD')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This metric is only valid if used in the context of `table` joined with `hourly_mean`, so let's do that. Writing down the join condition is seriously a matter of writing:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "join_expr = hour_dim == hourly_mean.hour"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now let's compute the MAD grouped by `string_col`"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "result = (table.inner_join(hourly_mean, join_expr)\n",
      "          .group_by(table.string_col)\n",
      "          .aggregate([mad]))\n",
      "result"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 19,
       "text": [
        "  string_col    mad\n",
        "0          7  25.25\n",
        "1          6  15.15\n",
        "2          4   5.05\n",
        "3          2  25.25\n",
        "4          8  35.35\n",
        "5          0  45.45\n",
        "6          3  15.15\n",
        "7          5   5.05\n",
        "8          9  45.45\n",
        "9          1  35.35"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Sorting\n",
      "===\n",
      "\n",
      "Sorting tables works similarly to the SQL `ORDER BY` clause. We use the `sort_by` function and pass one of the following:\n",
      "\n",
      "- Column names\n",
      "- Column expressions\n",
      "- One of these, with a False (descending order) or True (ascending order) qualifier\n",
      "\n",
      "So, to sort by `total` in ascending order we write:\n",
      "\n",
      "    table.sort_by('total')\n",
      "\n",
      "or by `key` then by `total` in descending order\n",
      "\n",
      "    table.sort_by(['key', ('total', False)])\n",
      "    \n",
      "For descending sort order, there is a convenience function `desc` which can wrap sort keys\n",
      "\n",
      "    from ibis import desc\n",
      "    table.sort_by(['key', desc(table.total)])"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here's a concrete example involving filters, custom grouping dimension, and sorting"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "table = con.table('functional.alltypes')\n",
      "\n",
      "keys = ['string_col', (table.bigint_col > 40).ifelse('high', 'low').name('bigint_tier')]\n",
      "metrics = [table.double_col.sum().name('total')]\n",
      "\n",
      "agged = (table\n",
      "         .filter(table.int_col < 8)\n",
      "         .group_by(keys)\n",
      "         .aggregate(metrics)\n",
      "         .sort_by(['bigint_tier', ('total', False)]))\n",
      "agged"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "  string_col bigint_tier  total\n",
        "0          7        high  51611\n",
        "1          6        high  44238\n",
        "2          5        high  36865\n",
        "3          4         low  29492\n",
        "4          3         low  22119\n",
        "5          2         low  14746\n",
        "6          1         low   7373\n",
        "7          0         low      0"
       ]
      }
     ],
     "prompt_number": 20
    }
   ],
   "metadata": {}
  }
 ]
}